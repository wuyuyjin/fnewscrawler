# MCPå·¥å…·å¼€å‘æŒ‡å—

## ğŸ“– æ¦‚è¿°

FNewsCrawler åŸºäº FastMCP æ¡†æ¶å®ç° Model Context Protocol (MCP) æœåŠ¡ï¼Œä¸ºå¤§æ¨¡å‹æä¾›æ ‡å‡†åŒ–çš„è´¢ç»æ•°æ®è®¿é—®æ¥å£ã€‚æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»äº† MCP å·¥å…·çš„å¼€å‘æµç¨‹ã€æ³¨å†Œæœºåˆ¶å’Œæœ€ä½³å®è·µã€‚

## ğŸ—ï¸ MCPæ¶æ„è®¾è®¡

### æ ¸å¿ƒç»„ä»¶

```
MCPæœåŠ¡æ¶æ„
â”œâ”€â”€ ğŸ§  FastMCP Server (mcp_server)
â”‚   â”œâ”€â”€ å·¥å…·æ³¨å†Œç®¡ç†
â”‚   â”œâ”€â”€ è¯·æ±‚è·¯ç”±åˆ†å‘
â”‚   â”œâ”€â”€ å‚æ•°éªŒè¯å¤„ç†
â”‚   â””â”€â”€ å“åº”æ ¼å¼åŒ–
â”‚
â”œâ”€â”€ ğŸ› ï¸ MCPManager (å•ä¾‹)
â”‚   â”œâ”€â”€ å·¥å…·çŠ¶æ€ç®¡ç†
â”‚   â”œâ”€â”€ å¯ç”¨/ç¦ç”¨æ§åˆ¶
â”‚   â”œâ”€â”€ RedisçŠ¶æ€æŒä¹…åŒ–
â”‚   â””â”€â”€ å·¥å…·ä¿¡æ¯æŸ¥è¯¢
â”‚
â”œâ”€â”€ ğŸ“¦ Tool Modules (æŒ‰åŸŸåç»„ç»‡)
â”‚   â”œâ”€â”€ iwencai/
â”‚   â”‚   â”œâ”€â”€ crawl.py     # MCPå·¥å…·å®ç°
â”‚   â”‚   â””â”€â”€ __init__.py  # å·¥å…·æ³¨å†Œ
â”‚   â”œâ”€â”€ eastmoney/
â”‚   â””â”€â”€ å…¶ä»–ç«™ç‚¹.../
â”‚
â””â”€â”€ ğŸ”Œ Auto Registration
    â”œâ”€â”€ Pythonå¯¼åŒ…æœºåˆ¶
    â”œâ”€â”€ è£…é¥°å™¨è‡ªåŠ¨æ³¨å†Œ
    â””â”€â”€ ç»Ÿä¸€mcp_serverå®ä¾‹
```

### è®¾è®¡åŸåˆ™

1. **ç»Ÿä¸€æ³¨å†Œæœºåˆ¶**ï¼šæ‰€æœ‰å·¥å…·é€šè¿‡ `fnewscrawler.mcp.mcp_server` å•ä¾‹å¯¹è±¡æ³¨å†Œ
2. **åŸŸåç»„ç»‡ç»“æ„**ï¼šæŒ‰ç›®æ ‡ç½‘ç«™åŸŸååˆ’åˆ†å·¥å…·æ¨¡å—ï¼Œä¿æŒä»£ç ç»„ç»‡æ¸…æ™°
3. **è‡ªåŠ¨å‘ç°æœºåˆ¶**ï¼šåˆ©ç”¨Pythonå¯¼åŒ…æœºåˆ¶å®ç°å·¥å…·çš„è‡ªåŠ¨æ³¨å†Œ
4. **çŠ¶æ€æŒä¹…åŒ–**ï¼šå·¥å…·å¯ç”¨/ç¦ç”¨çŠ¶æ€ä¿å­˜åˆ°Redisï¼Œæ”¯æŒåŠ¨æ€ç®¡ç†
5. **æ ‡å‡†åŒ–æ¥å£**ï¼šéµå¾ªMCPåè®®è§„èŒƒï¼Œç¡®ä¿ä¸å„ç§AIå®¢æˆ·ç«¯å…¼å®¹

## ğŸ§© æ ¸å¿ƒç»„ä»¶è¯¦è§£

### 1. mcp_server - MCPæœåŠ¡å®ä¾‹

**ä½ç½®**: `fnewscrawler/mcp/__init__.py`

```python
from fastmcp import FastMCP

# å…¨å±€å”¯ä¸€çš„MCPæœåŠ¡å™¨å®ä¾‹
mcp_server = FastMCP("FNewsCrawler")
```

**ç‰¹ç‚¹**:
- å…¨å±€å•ä¾‹ï¼Œç¡®ä¿æ‰€æœ‰å·¥å…·æ³¨å†Œåˆ°åŒä¸€æœåŠ¡å®ä¾‹
- åŸºäºFastMCPæ¡†æ¶ï¼Œæä¾›æ ‡å‡†MCPåè®®æ”¯æŒ
- è‡ªåŠ¨å¤„ç†å·¥å…·å‘ç°ã€å‚æ•°éªŒè¯å’Œå“åº”æ ¼å¼åŒ–

### 2. MCPManager - å·¥å…·ç®¡ç†å™¨

**ä½ç½®**: `fnewscrawler/mcp/mcp_manager.py`

**æ ¸å¿ƒåŠŸèƒ½**:
```python
class MCPManager:
    async def get_all_tools_info(self) -> list:
        """è·å–æ‰€æœ‰å·¥å…·ä¿¡æ¯"""
    
    async def get_tool_info(self, tool_name: str):
        """è·å–å•ä¸ªå·¥å…·ä¿¡æ¯"""
    
    async def enable_tool(self, tool_name: str) -> bool:
        """å¯ç”¨å·¥å…·"""
    
    async def disable_tool(self, tool_name: str) -> bool:
        """ç¦ç”¨å·¥å…·"""
    
    async def get_tool_status(self, tool_name: str) -> bool:
        """è·å–å·¥å…·çŠ¶æ€"""
```

## ğŸ“ ç›®å½•ç»“æ„è§„èŒƒ

### MCPå·¥å…·æ¨¡å—ç»„ç»‡

```
fnewscrawler/mcp/
â”œâ”€â”€ __init__.py                 # MCPæœåŠ¡å™¨å®ä¾‹å’Œç®¡ç†å™¨
â”œâ”€â”€ mcp_manager.py             # å·¥å…·ç®¡ç†å™¨å®ç°
â”œâ”€â”€ iwencai/                   # åŒèŠ±é¡ºé—®è´¢å·¥å…·
â”‚   â”œâ”€â”€ __init__.py           # å·¥å…·æ³¨å†Œå…¥å£
â”‚   â”œâ”€â”€ crawl.py              # çˆ¬è™«ç›¸å…³å·¥å…·
â”‚   â””â”€â”€ analysis.py           # åˆ†æç›¸å…³å·¥å…·ï¼ˆå¯é€‰ï¼‰
â”œâ”€â”€ eastmoney/                 # ä¸œæ–¹è´¢å¯Œå·¥å…·
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ crawl.py
â”‚   â””â”€â”€ market.py
â””â”€â”€ æ–°ç«™ç‚¹/                    # æ–°å¢ç«™ç‚¹å·¥å…·
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ crawl.py
    â””â”€â”€ å…¶ä»–åŠŸèƒ½.py
```

### æ–‡ä»¶å‘½åè§„èŒƒ

- **__init__.py**: å·¥å…·æ³¨å†Œå…¥å£ï¼Œå¯¼å…¥å…·ä½“å·¥å…·æ¨¡å—
- **crawl.py**: æ•°æ®çˆ¬å–ç›¸å…³çš„MCPå·¥å…·
- **analysis.py**: æ•°æ®åˆ†æç›¸å…³çš„MCPå·¥å…·
- **market.py**: å¸‚åœºæ•°æ®ç›¸å…³çš„MCPå·¥å…·
- **å…¶ä»–åŠŸèƒ½.py**: æ ¹æ®å®é™…éœ€è¦å‘½åçš„åŠŸèƒ½æ¨¡å—

## ğŸ› ï¸ å¼€å‘å®è·µ

### 1. åˆ›å»ºæ–°çš„MCPå·¥å…·æ¨¡å—

**æ­¥éª¤1: åˆ›å»ºç›®å½•ç»“æ„**
```bash
mkdir fnewscrawler/mcp/æ–°ç«™ç‚¹å
touch fnewscrawler/mcp/æ–°ç«™ç‚¹å/__init__.py
touch fnewscrawler/mcp/æ–°ç«™ç‚¹å/crawl.py
```

**æ­¥éª¤2: å®ç°MCPå·¥å…·**
```python
# fnewscrawler/mcp/æ–°ç«™ç‚¹å/crawl.py
from fnewscrawler.mcp import mcp_server
from fnewscrawler.spiders.æ–°ç«™ç‚¹å import new_site_crawl_from_query
from typing import List, Dict, Any

@mcp_server.tool()
async def new_site_news_query(query: str, page_no: int = 1) -> Dict[str, Any]:
    """
    ä»æ–°ç«™ç‚¹è·å–è´¢ç»æ–°é—»çš„ä¸“ä¸šæŸ¥è¯¢å·¥å…·
    
    è¿™æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è´¢ç»èµ„è®¯æŸ¥è¯¢å·¥å…·ï¼Œèƒ½å¤Ÿä»æ–°ç«™ç‚¹å®æ—¶è·å–æœ€æ–°çš„è´¢ç»æ–°é—»ä¿¡æ¯ã€‚
    è¯¥å·¥å…·ç‰¹åˆ«é€‚ç”¨äºè‚¡ç¥¨ç ”ç©¶ã€æŠ•èµ„åˆ†æå’Œè´¢ç»å¸‚åœºç›‘æ§ç­‰åœºæ™¯ã€‚
    
    ä¸»è¦åŠŸèƒ½ï¼š
    - å®æ—¶è·å–æ–°ç«™ç‚¹çš„æœ€æ–°è´¢ç»èµ„è®¯
    - æ”¯æŒè‚¡ç¥¨åç§°ã€è‚¡ç¥¨ä»£ç ã€è¡Œä¸šå…³é”®è¯ç­‰å¤šç§æŸ¥è¯¢æ–¹å¼
    - æŒ‰æ—¶é—´å€’åºè¿”å›æœ€ç›¸å…³çš„è´¢ç»æ–°é—»
    - åˆ†é¡µæŸ¥è¯¢æ”¯æŒï¼Œæé«˜æŸ¥è¯¢æ•ˆç‡
    
    é€‚ç”¨åœºæ™¯ï¼š
    - è‚¡ç¥¨åŸºæœ¬é¢åˆ†æå’Œç ”è°ƒ
    - è¡Œä¸šåŠ¨æ€è¿½è¸ªå’Œæ”¿ç­–è§£è¯»
    - æŠ•èµ„å†³ç­–æ”¯æŒå’Œé£é™©è¯„ä¼°
    - è´¢ç»äº‹ä»¶ç›‘æ§å’Œå¸‚åœºçƒ­ç‚¹åˆ†æ
    
    Args:
        query (str): æŸ¥è¯¢å…³é”®è¯ï¼Œæ”¯æŒä»¥ä¸‹ç±»å‹ï¼š
            - è‚¡ç¥¨åç§°ï¼šå¦‚"è´µå·èŒ…å°"ã€"æ¯”äºšè¿ª"ã€"è…¾è®¯æ§è‚¡"
            - è‚¡ç¥¨ä»£ç ï¼šå¦‚"600519"ã€"002594"ã€"00700"
            - è¡Œä¸šå…³é”®è¯ï¼šå¦‚"æ–°èƒ½æºæ±½è½¦"ã€"äººå·¥æ™ºèƒ½"ã€"åŠå¯¼ä½“"
            - è´¢ç»æ¦‚å¿µï¼šå¦‚"é™å‡†é™æ¯"ã€"IPOä¸Šå¸‚"ã€"å¹¶è´­é‡ç»„"
            - å®è§‚ç»æµï¼šå¦‚"GDPå¢é•¿"ã€"CPIæ•°æ®"ã€"å¤–æ±‡å‚¨å¤‡"
        
        page_no (int, optional): é¡µç ï¼Œé»˜è®¤ä¸º1ã€‚æ¯é¡µè¿”å›æ¡æ•°æ ¹æ®ç«™ç‚¹è€Œå®šã€‚
            - å»ºè®®ä¸è¶…è¿‡5é¡µä»¥ä¿æŒæŸ¥è¯¢æ•ˆç‡
            - é¡µç ä»1å¼€å§‹ï¼Œæ”¯æŒæ­£æ•´æ•°
    
    Returns:
        Dict[str, Any]: åŒ…å«ä»¥ä¸‹å­—æ®µçš„æŸ¥è¯¢ç»“æœï¼š
            - success (bool): æŸ¥è¯¢æ˜¯å¦æˆåŠŸ
            - data (List[Dict]): æ–°é—»åˆ—è¡¨ï¼Œæ¯æ¡æ–°é—»åŒ…å«ï¼š
                - title (str): æ–°é—»æ ‡é¢˜
                - content (str): æ–°é—»å†…å®¹æ‘˜è¦
                - url (str): æ–°é—»è¯¦æƒ…é“¾æ¥
                - time (str): å‘å¸ƒæ—¶é—´
                - source (str): æ–°é—»æ¥æºåª’ä½“
            - total (int): å½“å‰é¡µæ–°é—»æ•°é‡
            - page (int): å½“å‰é¡µç 
            - message (str): çŠ¶æ€æ¶ˆæ¯
    
    ä½¿ç”¨å»ºè®®ï¼š
    1. å¯¹äºçƒ­é—¨è‚¡ç¥¨ï¼Œå»ºè®®æŸ¥è¯¢å¤šé¡µè·å–å…¨é¢ä¿¡æ¯
    2. ä½¿ç”¨å…·ä½“çš„è‚¡ç¥¨ä»£ç å¯è·å¾—æ›´ç²¾å‡†çš„ç»“æœ
    3. è¡Œä¸šå…³é”®è¯æŸ¥è¯¢é€‚åˆäº†è§£æ¿å—æ•´ä½“åŠ¨æ€
    4. å»ºè®®ç»“åˆå¤šä¸ªå…³é”®è¯è¿›è¡Œäº¤å‰éªŒè¯
    
    ç¤ºä¾‹ï¼š
        # æŸ¥è¯¢ç‰¹å®šè‚¡ç¥¨
        result = await new_site_news_query("è´µå·èŒ…å°", 1)
        
        # æŸ¥è¯¢è¡Œä¸šåŠ¨æ€
        result = await new_site_news_query("æ–°èƒ½æºæ±½è½¦", 1)
        
        # æŸ¥è¯¢å®è§‚ç»æµ
        result = await new_site_news_query("å¤®è¡Œæ”¿ç­–", 1)
    """
    try:
        # è°ƒç”¨çˆ¬è™«å‡½æ•°è·å–æ•°æ®
        news_list = await new_site_crawl_from_query(query, page_no)
        
        # æ ¼å¼åŒ–è¿”å›ç»“æœ
        return {
            "success": True,
            "data": news_list,
            "total": len(news_list),
            "page": page_no,
            "message": f"æˆåŠŸè·å– {len(news_list)} æ¡æ–°é—»"
        }
        
    except Exception as e:
        return {
            "success": False,
            "data": [],
            "total": 0,
            "page": page_no,
            "message": f"æŸ¥è¯¢å¤±è´¥: {str(e)}"
        }

@mcp_server.tool()
async def new_site_market_data(symbol: str) -> Dict[str, Any]:
    """
    è·å–æ–°ç«™ç‚¹çš„å¸‚åœºæ•°æ®
    
    Args:
        symbol (str): è‚¡ç¥¨ä»£ç æˆ–åç§°
    
    Returns:
        Dict[str, Any]: å¸‚åœºæ•°æ®ç»“æœ
    """
    try:
        # å®ç°å¸‚åœºæ•°æ®è·å–é€»è¾‘
        # market_data = await get_market_data(symbol)
        
        return {
            "success": True,
            "data": {},  # å®é™…çš„å¸‚åœºæ•°æ®
            "message": "å¸‚åœºæ•°æ®è·å–æˆåŠŸ"
        }
        
    except Exception as e:
        return {
            "success": False,
            "data": {},
            "message": f"è·å–å¸‚åœºæ•°æ®å¤±è´¥: {str(e)}"
        }
```

**æ­¥éª¤3: é…ç½®å·¥å…·æ³¨å†Œ**
```python
# fnewscrawler/mcp/æ–°ç«™ç‚¹å/__init__.py

# å¯¼å…¥å·¥å…·æ¨¡å—ï¼Œåˆ©ç”¨Pythonå¯¼åŒ…æœºåˆ¶å®Œæˆå·¥å…·æ³¨å†Œ
import fnewscrawler.mcp.æ–°ç«™ç‚¹å.crawl

# å¦‚æœ‰å…¶ä»–å·¥å…·æ¨¡å—ï¼Œä¹Ÿåœ¨æ­¤å¯¼å…¥
# import fnewscrawler.mcp.æ–°ç«™ç‚¹å.analysis
# import fnewscrawler.mcp.æ–°ç«™ç‚¹å.market
```

**æ­¥éª¤4: æ›´æ–°ä¸»MCPæ¨¡å—**
```python
# fnewscrawler/mcp/__init__.py
from fastmcp import FastMCP
mcp_server = FastMCP("FNewsCrawler")
from .mcp_manager import MCPManager

# å°†å­åŒ…ä¸‹çš„mcpå·¥å…·æ›´æ–°è¿›æ¥
import fnewscrawler.mcp.iwencai
import fnewscrawler.mcp.æ–°ç«™ç‚¹å  # æ·»åŠ æ–°ç«™ç‚¹å¯¼å…¥

__all__ = [
    "mcp_server",
    "MCPManager"
]
```

### 2. å·¥å…·å¼€å‘æœ€ä½³å®è·µ

#### å·¥å…·å‘½åè§„èŒƒ
```python
# å¥½çš„å‘½åï¼šç«™ç‚¹å_åŠŸèƒ½_åŠ¨ä½œ
@mcp_server.tool()
async def iwencai_news_query(...):
    pass

@mcp_server.tool()
async def eastmoney_market_data(...):
    pass

@mcp_server.tool()
async def sina_stock_analysis(...):
    pass
```

#### æ–‡æ¡£å­—ç¬¦ä¸²è§„èŒƒ
```python
@mcp_server.tool()
async def example_tool(param1: str, param2: int = 1) -> Dict[str, Any]:
    """
    å·¥å…·çš„ç®€çŸ­æè¿°ï¼ˆä¸€è¡Œï¼‰
    
    è¯¦ç»†çš„å·¥å…·æè¿°ï¼ŒåŒ…æ‹¬ï¼š
    - ä¸»è¦åŠŸèƒ½å’Œç”¨é€”
    - é€‚ç”¨åœºæ™¯
    - æ•°æ®æ¥æºè¯´æ˜
    
    Args:
        param1 (str): å‚æ•°1çš„è¯¦ç»†è¯´æ˜ï¼ŒåŒ…æ‹¬ï¼š
            - å‚æ•°çš„ä½œç”¨å’Œæ„ä¹‰
            - æ”¯æŒçš„æ ¼å¼å’Œç¤ºä¾‹
            - ç‰¹æ®Šè¦æ±‚æˆ–é™åˆ¶
        param2 (int, optional): å‚æ•°2çš„è¯´æ˜ï¼Œé»˜è®¤å€¼ä¸º1
    
    Returns:
        Dict[str, Any]: è¿”å›ç»“æœçš„è¯¦ç»†è¯´æ˜ï¼š
            - success (bool): æ“ä½œæ˜¯å¦æˆåŠŸ
            - data: å…·ä½“çš„æ•°æ®ç»“æ„è¯´æ˜
            - message (str): çŠ¶æ€æ¶ˆæ¯
    
    ä½¿ç”¨å»ºè®®ï¼š
    1. å…·ä½“çš„ä½¿ç”¨å»ºè®®
    2. æ€§èƒ½ä¼˜åŒ–æç¤º
    3. æ³¨æ„äº‹é¡¹
    
    ç¤ºä¾‹ï¼š
        result = await example_tool("ç¤ºä¾‹å‚æ•°", 2)
    """
    pass
```

#### é”™è¯¯å¤„ç†æ¨¡å¼
```python
@mcp_server.tool()
async def robust_tool(query: str) -> Dict[str, Any]:
    """å¥å£®çš„å·¥å…·å®ç°"""
    try:
        # å‚æ•°éªŒè¯
        if not query or not query.strip():
            return {
                "success": False,
                "data": [],
                "message": "æŸ¥è¯¢å‚æ•°ä¸èƒ½ä¸ºç©º"
            }
        
        # æ ¸å¿ƒä¸šåŠ¡é€»è¾‘
        result = await some_crawl_function(query)
        
        # ç»“æœéªŒè¯
        if not result:
            return {
                "success": True,
                "data": [],
                "message": "æœªæ‰¾åˆ°ç›¸å…³æ•°æ®"
            }
        
        # æˆåŠŸè¿”å›
        return {
            "success": True,
            "data": result,
            "total": len(result),
            "message": f"æˆåŠŸè·å– {len(result)} æ¡æ•°æ®"
        }
        
    except Exception as e:
        # è®°å½•é”™è¯¯æ—¥å¿—
        from fnewscrawler.utils.logger import LOGGER
        LOGGER.error(f"å·¥å…·æ‰§è¡Œå¤±è´¥: {e}")
        
        # è¿”å›é”™è¯¯ä¿¡æ¯
        return {
            "success": False,
            "data": [],
            "message": f"æ‰§è¡Œå¤±è´¥: {str(e)}"
        }
```

#### è¿”å›æ•°æ®æ ‡å‡†åŒ–
```python
# æ ‡å‡†è¿”å›æ ¼å¼
{
    "success": bool,        # æ“ä½œæ˜¯å¦æˆåŠŸ
    "data": Any,           # å…·ä½“æ•°æ®ï¼Œç±»å‹æ ¹æ®å·¥å…·è€Œå®š
    "message": str,        # çŠ¶æ€æ¶ˆæ¯
    "total": int,          # æ•°æ®æ€»æ•°ï¼ˆå¯é€‰ï¼‰
    "page": int,           # å½“å‰é¡µç ï¼ˆå¯é€‰ï¼‰
    "timestamp": str       # æ—¶é—´æˆ³ï¼ˆå¯é€‰ï¼‰
}

# æ–°é—»æ•°æ®æ ¼å¼
{
    "title": str,          # æ–°é—»æ ‡é¢˜
    "content": str,        # æ–°é—»å†…å®¹æˆ–æ‘˜è¦
    "url": str,            # æ–°é—»é“¾æ¥
    "time": str,           # å‘å¸ƒæ—¶é—´
    "source": str,         # æ–°é—»æ¥æº
    "tags": List[str]      # æ ‡ç­¾ï¼ˆå¯é€‰ï¼‰
}

# å¸‚åœºæ•°æ®æ ¼å¼
{
    "symbol": str,         # è‚¡ç¥¨ä»£ç 
    "name": str,           # è‚¡ç¥¨åç§°
    "price": float,        # å½“å‰ä»·æ ¼
    "change": float,       # æ¶¨è·Œé¢
    "change_percent": float, # æ¶¨è·Œå¹…
    "volume": int,         # æˆäº¤é‡
    "timestamp": str       # æ•°æ®æ—¶é—´
}
```

### 3. å·¥å…·æµ‹è¯•

#### å•å…ƒæµ‹è¯•
```python
# test/mcp/test_new_site_tools.py
import pytest
from fnewscrawler.mcp.æ–°ç«™ç‚¹å.crawl import new_site_news_query

@pytest.mark.asyncio
async def test_news_query_success():
    """æµ‹è¯•æ–°é—»æŸ¥è¯¢æˆåŠŸåœºæ™¯"""
    result = await new_site_news_query("æµ‹è¯•æŸ¥è¯¢", 1)
    
    assert isinstance(result, dict)
    assert "success" in result
    assert "data" in result
    assert "message" in result
    
    if result["success"]:
        assert isinstance(result["data"], list)
        if result["data"]:
            news_item = result["data"][0]
            assert "title" in news_item
            assert "url" in news_item

@pytest.mark.asyncio
async def test_news_query_empty_param():
    """æµ‹è¯•ç©ºå‚æ•°åœºæ™¯"""
    result = await new_site_news_query("", 1)
    
    assert result["success"] is False
    assert "å‚æ•°ä¸èƒ½ä¸ºç©º" in result["message"]

@pytest.mark.asyncio
async def test_news_query_invalid_page():
    """æµ‹è¯•æ— æ•ˆé¡µç åœºæ™¯"""
    result = await new_site_news_query("æµ‹è¯•", 0)
    
    # æ ¹æ®å®é™…å®ç°è°ƒæ•´æ–­è¨€
    assert isinstance(result, dict)
```

#### é›†æˆæµ‹è¯•
```python
@pytest.mark.asyncio
async def test_mcp_server_integration():
    """æµ‹è¯•MCPæœåŠ¡å™¨é›†æˆ"""
    from fnewscrawler.mcp import mcp_server
    
    # è·å–æ‰€æœ‰å·¥å…·
    tools = await mcp_server.get_tools()
    
    # éªŒè¯æ–°å·¥å…·å·²æ³¨å†Œ
    assert "new_site_news_query" in tools
    
    # æµ‹è¯•å·¥å…·è°ƒç”¨
    result = await mcp_server.call_tool(
        "new_site_news_query",
        query="æµ‹è¯•",
        page_no=1
    )
    
    assert isinstance(result, dict)
```

### 4. å·¥å…·ç®¡ç†

#### åŠ¨æ€å¯ç”¨/ç¦ç”¨
```python
from fnewscrawler.mcp.mcp_manager import MCPManager

manager = MCPManager()

# ç¦ç”¨å·¥å…·
await manager.disable_tool("new_site_news_query")

# å¯ç”¨å·¥å…·
await manager.enable_tool("new_site_news_query")

# æ£€æŸ¥å·¥å…·çŠ¶æ€
status = await manager.get_tool_status("new_site_news_query")
```

#### Webç•Œé¢ç®¡ç†
è®¿é—® `http://localhost:8480/mcp` è¿›è¡Œå¯è§†åŒ–ç®¡ç†ï¼š
- æŸ¥çœ‹æ‰€æœ‰å·²æ³¨å†Œçš„å·¥å…·
- åŠ¨æ€å¯ç”¨/ç¦ç”¨å·¥å…·
- æŸ¥çœ‹å·¥å…·è¯¦ç»†ä¿¡æ¯
- æ‰¹é‡æ“ä½œå·¥å…·çŠ¶æ€

## ğŸ”§ é«˜çº§ç‰¹æ€§

### 1. å·¥å…·å‚æ•°éªŒè¯
```python
from pydantic import BaseModel, validator
from typing import Optional

class NewsQueryParams(BaseModel):
    query: str
    page_no: Optional[int] = 1
    
    @validator('query')
    def query_must_not_be_empty(cls, v):
        if not v or not v.strip():
            raise ValueError('æŸ¥è¯¢å‚æ•°ä¸èƒ½ä¸ºç©º')
        return v.strip()
    
    @validator('page_no')
    def page_no_must_be_positive(cls, v):
        if v < 1:
            raise ValueError('é¡µç å¿…é¡»å¤§äº0')
        return v

@mcp_server.tool()
async def validated_news_query(params: NewsQueryParams) -> Dict[str, Any]:
    """å¸¦å‚æ•°éªŒè¯çš„æ–°é—»æŸ¥è¯¢å·¥å…·"""
    # å‚æ•°å·²é€šè¿‡PydanticéªŒè¯
    return await some_crawl_function(params.query, params.page_no)
```

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–

### 1. å¼‚æ­¥å¹¶å‘
```python
import asyncio
from typing import List

@mcp_server.tool()
async def batch_news_query(queries: List[str]) -> Dict[str, Any]:
    """æ‰¹é‡æ–°é—»æŸ¥è¯¢"""
    try:
        # å¹¶å‘æ‰§è¡Œå¤šä¸ªæŸ¥è¯¢
        tasks = [some_crawl_function(query) for query in queries]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # å¤„ç†ç»“æœ
        success_results = []
        failed_queries = []
        
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                failed_queries.append(queries[i])
            else:
                success_results.extend(result)
        
        return {
            "success": True,
            "data": success_results,
            "total": len(success_results),
            "failed_queries": failed_queries,
            "message": f"æˆåŠŸæŸ¥è¯¢ {len(queries) - len(failed_queries)}/{len(queries)} ä¸ªå…³é”®è¯"
        }
        
    except Exception as e:
        return {
            "success": False,
            "data": [],
            "message": f"æ‰¹é‡æŸ¥è¯¢å¤±è´¥: {str(e)}"
        }
```



## ğŸ“‹ å¼€å‘æ£€æŸ¥æ¸…å•

å¼€å‘æ–°MCPå·¥å…·æ—¶ï¼Œè¯·ç¡®ä¿å®Œæˆä»¥ä¸‹æ£€æŸ¥ï¼š

### åŸºç¡€å¼€å‘
- [ ] æŒ‰åŸŸååˆ›å»ºMCPå·¥å…·ç›®å½•
- [ ] å®ç°å·¥å…·å‡½æ•°å¹¶æ·»åŠ  `@mcp_server.tool()` è£…é¥°å™¨
- [ ] ç¼–å†™è¯¦ç»†çš„æ–‡æ¡£å­—ç¬¦ä¸²
- [ ] é…ç½®å·¥å…·æ³¨å†Œï¼ˆ__init__.pyï¼‰
- [ ] æ›´æ–°ä¸»MCPæ¨¡å—å¯¼å…¥

### ä»£ç è´¨é‡
- [ ] æ·»åŠ é€‚å½“çš„é”™è¯¯å¤„ç†
- [ ] å®ç°æ ‡å‡†åŒ–çš„è¿”å›æ ¼å¼
- [ ] æ·»åŠ å‚æ•°éªŒè¯
- [ ] ç¼–å†™å•å…ƒæµ‹è¯•
- [ ] ç¼–å†™é›†æˆæµ‹è¯•

### æ€§èƒ½ä¼˜åŒ–
- [ ] è€ƒè™‘æ·»åŠ ç¼“å­˜æœºåˆ¶
- [ ] å®ç°å¹¶å‘æ§åˆ¶
- [ ] æ·»åŠ ç›‘æ§å’Œæ—¥å¿—
- [ ] æ€§èƒ½æµ‹è¯•å’Œä¼˜åŒ–

### æ–‡æ¡£å’Œéƒ¨ç½²
- [ ] æ›´æ–°å·¥å…·ä½¿ç”¨æ–‡æ¡£
- [ ] æµ‹è¯•Webç•Œé¢ç®¡ç†åŠŸèƒ½
- [ ] éªŒè¯å·¥å…·å¯ç”¨/ç¦ç”¨åŠŸèƒ½
- [ ] ç¡®è®¤MCPå®¢æˆ·ç«¯å…¼å®¹æ€§

## ğŸ” è°ƒè¯•æŠ€å·§

### 1. æœ¬åœ°æµ‹è¯•
```python
# ç›´æ¥æµ‹è¯•å·¥å…·å‡½æ•°
from fnewscrawler.mcp.æ–°ç«™ç‚¹å.crawl import new_site_news_query

result = await new_site_news_query("æµ‹è¯•æŸ¥è¯¢", 1)
print(result)
```

### 2. MCPæœåŠ¡å™¨æµ‹è¯•
```python
from fnewscrawler.mcp import mcp_server

# æµ‹è¯•å·¥å…·æ³¨å†Œ
tools = await mcp_server.get_tools()
print("å·²æ³¨å†Œçš„å·¥å…·:", list(tools.keys()))

# æµ‹è¯•å·¥å…·è°ƒç”¨
result = await mcp_server.call_tool(
    "new_site_news_query",
    query="æµ‹è¯•",
    page_no=1
)
print("è°ƒç”¨ç»“æœ:", result)
```

### 3. Webç•Œé¢è°ƒè¯•
1. å¯åŠ¨WebæœåŠ¡ï¼š`python main.py`
2. è®¿é—® `http://localhost:8480/mcp`
3. æŸ¥çœ‹å·¥å…·åˆ—è¡¨å’ŒçŠ¶æ€
4. æµ‹è¯•å·¥å…·å¯ç”¨/ç¦ç”¨åŠŸèƒ½

---

é€šè¿‡éµå¾ªæœ¬æŒ‡å—ï¼Œæ‚¨å¯ä»¥é«˜æ•ˆåœ°å¼€å‘å‡ºç¬¦åˆMCPåè®®æ ‡å‡†çš„è´¢ç»æ•°æ®å·¥å…·ï¼Œä¸ºå¤§æ¨¡å‹æä¾›ä¸“ä¸šçš„æ•°æ®æ”¯æŒã€‚å¦‚æœ‰ç–‘é—®ï¼Œè¯·å‚è€ƒç°æœ‰çš„ `iwencai` å·¥å…·å®ç°æˆ–æäº¤ Issue å¯»æ±‚å¸®åŠ©ã€‚